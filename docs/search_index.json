[["index.html", "NMHS_APP Introduction", " NMHS_APP Deepan P 2024-09-14 Introduction Due to time constraints, there was an immediate need for clean and accurate sample selection from a high-volume dataset. This requirement led to the development of this application. Sampling had to be carried out for all the States and Union Territories, further stratified into Rural and Urban segments, as per the sampling strategy flowchart shown below. The overall study design For a specific State, once the districts where the survey is to be conducted are finalized: For the Rural population: The list of Gram Panchayats (GP) under each selected district was obtained from the Jal Jeevan Mission portal (JJM Reports), which provides projected population sizes of SC, ST, and General categories based on the 2011 census. The issue with the JJM reports was that the GP data was provided as separate spreadsheets (.xls) at the development block level according to the administrative system, rather than as a single list for each district. Therefore, the first phase of GP selection involves merging several block‑level data files into one consolidated list using the function TableCooker of PPS.xlsm, in order to obtain the projected total rural population of each selected district within a state for calculating the number of clusters and Probability proportional size was adopted for the allocation of number of clusters on each district.Probability Proportional to Size (PPS) was then adopted for allocating the number of clusters to each district. For the Urban population: According to the study design, the Urban population was further divided into Million Plus (MP) and Non‑Million Plus (NMP) cities. The application was developed to handle only NMP cities, while MP cities were managed manually without any automation. Therefore, this documentation focuses solely on the NMP cities. Sampling was carried out using Urban Frame Sampling (UFS) block‑level data obtained from the Ministry of Statistics and Programme Implementation website (UFS metadata), which provides state‑wise UFS block data. The important definitions related the UFS metadata is provided in the below PDF (pg.no: 2). Term Definition (Summary) House Any structure, tent, or shelter used for residential, non‑residential, or both purposes; it may also be vacant. Household A group of people normally living together and sharing a common kitchen; members may or may not be related by blood. Block The ultimate unit of enumeration in UFS; a compact area bounded by natural or permanent landmarks. Each typically contains ~120–150 households. A block is bounded by well‑defined, clear‑cut, natural boundaries to the extent possible. Blocks are mutually exclusive and exhaustive, so that all blocks in a town together cover the town’s total area. (Equivalent to a village in rural areas) Investigator Unit (IV Unit) An intermediate unit between a town and its blocks; consists of ~20–40 UFS blocks and, where available, follows ward boundaries. (Equivalent to a Gram Panchayat in rural areas) Each district in the urban scenario has several IV units, similar to Gram Panchayats (GP) in rural areas. However, as per the definitions above, in reality some IV units were not valid—i.e., in certain cases, we found IV units with fewer than 20 UFS blocks. Hence, these IV units were excluded when preparing the number of IV units for each district during the PPS calculation and cluster allocation process. On the other hand, in some cases, the exclusion of IV units due to an insufficient number of UFS blocks led to the exclusion of an entire selected district especially in NMP cites. This serious issue was managed by slightly tweaking the program: in such cases, the “excluder” was turned off, allowing clusters to be selected repeatedly from the same limited IV units. In other cases, the rule was maintained—choosing only one cluster (i.e., UFS blocks) from which 25 adults and 10 adolescents would be selected in each cluster, similar to the approach used in villages, which serve as clusters in rural areas. To address the infeasibility caused by the identification of ST populations in rural scenario and inaccessible UFS blocks in urban scenario or not able to achieve the target of 25 adults and 10 adolescents, more than one selection list (i.e., 3) of clusters was provided to the field data collectors. They were instructed to follow only one list under normal circumstances and use the other list in exceptional situations. they can use the other list to choose another cluster belong to the same Gram Panchayat or IV unit. "],["cluster-selection-in-rural-areas.html", "Cluster selection in Rural areas Overview PHASE 1: Data Collection and Consolidation (First Pass) PHASE 2: Proportional Analysis and Sampling Preparation PHASE 3: Systematic Sampling and Results Generation (Second Pass)", " Cluster selection in Rural areas This section discusses the implementation of the app for cluster selection in rural areas. File structure State xyz / ├── Cluster Allocation.xlsm ├── District a / │ ├── PPS.xlsm │ ├── Block 1 data.xls │ ├── Block 2 data.xls │ ├── Block 3 data.xls │ ├── : │ └── : ├── District b / ├── District c / ├── : └── : Cluster Allocation.xlsm is present in all the state folders, and PPS.xlsm is present in all the district folders under each state. Block 1 data.xls contains the list of Gram Panchayats as shown in below. Functions Cluster ALLocation.xlsm ├── Module1 │ ├── func ALLinALL() │ └── func FilterByColor(PPSWorkbook As Workbook) └── Module2 └── func CalculateProportions() PPS.xlsm ├── Module1 │ └── func CopySheetsFromAllWorkbooks() ├── Module2 │ └── func TableCooker() ├── Module3 │ └── func CumulativeSumWithFormula() ├── Module4 │ └── func RandomSelector() └── Module5 └── func LoadTotal() * highlighted functions are the main tasks where the other functions are subtasks Program Flow chart Code knitr::include_graphics(&quot;flow-chart2.svg&quot;) Overview The ALLinALL macro implements a sophisticated three-phase data processing and sampling system designed for multi-directory statistical analysis. The system processes Excel files across multiple folders, consolidates data, calculates proportional distributions, and performs systematic sampling with multiple iterations. PHASE 1: Data Collection and Consolidation (First Pass) Purpose This phase discovers and processes data files across directory structures, creating a unified dataset for sampling procedure. Detailed Procedures 1.1 Directory Scanning and Setup currentDirectory = ThisWorkbook.Path dirName = Mid(currentDirectory, InStrRev(currentDirectory, &quot;\\&quot;) + 1) Function: Identifies the current working directory and extracts just the directory name Output: Creates a base reference for grouping data by location Data Flow: Directory name goes to Column A of the main worksheet 1.2 Folder Iteration and File Discovery For Each folder In fileSystem.GetFolder(currentDirectory).SubFolders PPSPath = folder.Path &amp; &quot;\\&quot; &amp; PPSFile Function: Systematically searches each subfolder for PPS.xlsm files Logic: Uses FileSystemObject for robust file system navigation Error Handling: Checks file existence with Dir(PPSPath) &lt;&gt; \"\" Data Flow: Folder names populate Column B of main worksheet ::: {align=“center”} ::: 1.3 TableCooker Execution (Core Data Processing) When a PPS.xlsm file is found, the system executes the `TableCooker` macro: Sub-Process: CopySheetsFromAllWorkbooks fileName = Dir(folderPath &amp; &quot;*.xls&quot;) Do While fileName &lt;&gt; &quot;&quot; For Each ws In sourceWorkbook.Sheets ws.Copy After:=currentWorkbook.Sheets(currentWorkbook.Sheets.Count) Function: Discovers and imports all Excel files (.xls) within each folder Logic: Creates a comprehensive dataset by merging multiple source files Sr. No. Gram Panchayat TOTAL C.P Selection 1 BIRSIEJ 750 2 I.C.A.R. 836 3 INGSAW 1184 4 ITPATUNG 131 5 ITSOHPAIR 710 Exclusion Rule: Skips the current workbook to avoid circular references Sub-Process: Data Standardization ws.Rows(&quot;1:6&quot;).Delete &#39; Remove headers ws.Rows(lastRow - 1 &amp; &quot;:&quot; &amp; lastRow).Delete &#39; Remove footers Function: Standardizes data structure across different source files Rationale: Removes inconsistent header/footer rows that vary between files Result: Clean, uniform data ready for statistical processing Sub-Process: Data Consolidation usedRange.Copy combinedSheet.Cells(lastTargetRow, 1).PasteSpecial Paste:=xlPasteValues Function: Merges all processed sheets into a single “CombinedData” sheet Method: Sequential appending maintains data integrity Memory Management: Uses PasteSpecial with values only to optimize performance 1.4 Statistical Preprocessing Cumulative Sum Calculation Range(&quot;G2&quot;).Value = Range(&quot;F2&quot;).Value .Range(&quot;G3&quot;, &quot;G&quot; &amp; ws.Rows.Count).Formula = &quot;=&quot; &amp; .Cells(3, &quot;F&quot;).Address &amp; &quot;+&quot; &amp; .Cells(2, &quot;G&quot;).Address Function: Creates running totals essential for systematic sampling Total Extraction total = ws.Cells(lastRow, &quot;G&quot;).Value ws.Range(&quot;O1&quot;).Value = total Function: Captures the final cumulative total for each dataset Storage: Places total in cell O1 for cross-reference Data Flow: This total becomes the basis for proportional calculations Phase 1 Output Column A: Directory name (grouping variable) Column B: Folder name (district identifier) Column C: Total values from each folder’s processed data Result: Master inventory of all available data sources with their statistical weights PHASE 2: Proportional Analysis and Sampling Preparation Purpose Calculates proportional distributions and determines sampling allocations based on collected data. Detailed Procedures 2.1 User Input Integration - total clusters requested userValue = Application.InputBox(&quot;Enter Total No. of clusters:&quot;, Type:=1) Integration: Multiplies proportions to determine actual number of clusters for each district 2.2 CalculateProportions Function Proportion Calculation ws.Cells(j, &quot;D&quot;).Value = ws.Cells(j, &quot;C&quot;).Value / sumC ws.Cells(j, &quot;E&quot;).Value = ws.Cells(j, &quot;D&quot;).Value * userValue Column D: Relative proportion (folder total ÷ directory total) Column E: Absolute allocation (proportion × total clusters requested) Column F: Rounded off values of Column E Phase 2 Output Column D: Proportional weights (0-1 scale) Column E: Actual cluster counts for sampling Purpose: Provides sampling parameters for Phase 3 execution PHASE 3: Systematic Sampling and Results Generation (Second Pass) Purpose Executes multiple iterations of systematic sampling across all data sources and generates comprehensive results. Detailed Procedures 3.1 Sampling Preparation Set PPSWorkbook = Workbooks.Open(PPSPath) valueForMacro = ws.Cells(rowCounter, 5).Value PPSWorkbook.Sheets(1).Range(&quot;O2&quot;).Value = valueForMacro Function: Reopens each PPS file for sampling Parameter Passing: Transfers calculated sample sizes (Column E) to O2 Setup: Prepares the sampling environment with correct parameters 3.2 Results Sheet Creation Set wsNew = ThisWorkbook.Sheets.Add(After:=ThisWorkbook.Sheets(ThisWorkbook.Sheets.Count)) wsNew.Name = folderName Function: Creates dedicated output sheets for each folder Organization: Maintains clear separation of results by data source Naming: Uses folder names for easy identification 3.3 RandomSelector Algorithm (Core Sampling Engine) Initialization and Cleanup ws.Columns(&quot;B:B&quot;).Interior.Color = xlNone Range(&quot;O5:O20&quot;).Delete Shift:=xlUp userInput = ws.Range(&quot;O2&quot;).Value Reset: Clears previous color coding and random values Parameter Loading: Gets sample size from Phase 2 calculations Preparation: Sets up clean environment for new sampling iteration Sampling Interval Calculation total = ws.Cells(lastRow, &quot;G&quot;).Value ws.Range(&quot;O3&quot;).Value = total / userInput O1Value = ws.Range(&quot;O3&quot;).Value Function: Calculates systematic sampling interval Formula: Total population ÷ desired sample size Random Start Generation and Selection rand_start = Rnd() * O1Value Do While counter &lt; userInput For i = 2 To lastRow If ws.Cells(i, &quot;G&quot;).Value &gt; rand_start Then ws.Cells(i, &quot;B&quot;).Interior.Color = RGB(255, 255, 0) &#39; Yellow rand_start = rand_start + O1Value counter = counter + 1 Random Start: Generates random starting point within first interval Systematic Selection: Adds interval size to select subsequent items Visual Marking: Colors selected rows yellow for identification Iteration Control: Continues until desired sample size reached 3.4 Multi-Iteration Processing For iterationcounter = 1 To repeatTimes Application.Run &quot;&#39;&quot; &amp; PPSWorkbook.Name &amp; &quot;&#39;!RandomSelector&quot; PPSWorkbook.Sheets(1).Range(&quot;M:O&quot;).Copy wsNew.Cells(1, pasteMOColumn) Function: Runs multiple independent sampling iterations Output Management: Places results side-by-side for comparison 3.5 FilterByColor and Data Extraction ws.Range(&quot;A1:H&quot; &amp; lastRow).AutoFilter field:=2, Criteria1:=RGB(255, 255, 0), Operator:=xlFilterCellColor Set visibleRange = filteredRange.SpecialCells(xlCellTypeVisible) visibleRange.Copy wsNew.Cells(1, pasteTableColumn) Function: Isolates selected (yellow) rows from the dataset Method: Uses Excel’s AutoFilter with color criteria Extraction: Copies only visible (selected) rows to results Layout: Arranges multiple iterations horizontally for analysis "],["cluster-selection-in-urban-areas.html", "Cluster selection in Urban areas Import Libraries and Utility Functions Data Download and Initial Processing District Selection and Filtering Exclusion Logic Cluster Calculation and Proportional Allocation Utility Functions for Report Generation Result Summary and Sampling Preparation Random Cluster Sampling Implementation Geographic Coordinate Assignment (Geocoding) Output Generation and Final Documentation", " Cluster selection in Urban areas Program Flow chart Code knitr::include_graphics(&quot;flow-chart.svg&quot;) Code # Install Python packages via pip system(&quot;pip install requests pandas geopy openpyxl geopandas matplotlib numpy reportlab PyPDF2&quot;) # Download files from Google Drive using gdown system(&quot;gdown https://drive.google.com/uc?id=1BQnzVmLHCfw84z-RnfWbdgcpNIBNgKWc&quot;) system(&quot;gdown https://drive.google.com/uc?id=18L5b_ya_YxoD7-PCfw8ftzeXU0jh6BIy&quot;) # Make directory dir.create(&quot;GIS map temp&quot;, showWarnings = FALSE) # Unzip file unzip(&quot;district_boundries.zip&quot;, exdir = &quot;GIS&quot;) # Remove zip file unlink(&quot;district_boundries.zip&quot;) # Remove folder unlink(&quot;sample_data&quot;, recursive = TRUE) Import Libraries and Utility Functions This section imports all necessary libraries for data processing, file operations, geographic analysis, visualization, and PDF generation. It also includes utility functions for: File Download: Download files from URLs with error handling and progress tracking Random Filename Generation: Create unique filenames to avoid conflicts during file operations Key Libraries: - pandas, numpy: Data manipulation and analysis - geopandas, geopy: Geographic data processing - matplotlib: Data visualization - reportlab, PyPDF2: PDF generation and manipulation - requests: HTTP requests for file downloads - openpyxl: Excel file operations Code import requests import os import random import string import pandas as pd import geopy from openpyxl import Workbook import geopandas as gpd import matplotlib.pyplot as plt import numpy as np from collections import Counter import warnings from reportlab.lib import colors from reportlab.lib.pagesizes import A4 from reportlab.lib.units import inch from reportlab.pdfgen import canvas from reportlab.pdfbase import pdfmetrics from reportlab.pdfbase.ttfonts import TTFont from reportlab.platypus import Table, TableStyle, SimpleDocTemplate from PyPDF2 import PdfWriter, PdfReader from IPython.display import display # Suppress specific warnings to keep output clean warnings.filterwarnings(&#39;ignore&#39;) def download_file(url, folder_path, filename): &quot;&quot;&quot; Download a file from URL and save it to specified folder Returns: filepath if successful, None if failed &quot;&quot;&quot; try: # Create directory if it doesn&#39;t exist if not os.path.exists(folder_path): os.makedirs(folder_path) print(f&quot;✓ Created directory: {folder_path}&quot;) # Download file with streaming to handle large files response = requests.get(url, stream=True) response.raise_for_status() filepath = os.path.join(folder_path, filename) with open(filepath, &#39;wb&#39;) as file: for chunk in response.iter_content(chunk_size=8192): file.write(chunk) print(f&quot;✓ File downloaded successfully: {filepath}&quot;) return filepath except requests.exceptions.RequestException as e: print(f&quot;✗ Error downloading file: {e}&quot;) return None def generate_random_filename(length=10, extension=&quot;.xlsx&quot;): &quot;&quot;&quot;Generate a random filename to avoid conflicts&quot;&quot;&quot; characters = string.ascii_letters + string.digits random_filename = &#39;&#39;.join(random.choice(characters) for _ in range(length)) + extension return random_filename Data Download and Initial Processing This step handles the initial data acquisition and preprocessing: Key Operations: 1. Download Data: Downloads UFS (Urban Frame Survey) data from MOSPI website for Goa state 2. Load Excel File: Reads the downloaded Excel file into a pandas DataFrame 3. Clean Headers: Removes metadata rows and assigns meaningful column names 4. Extract State Info: Captures state name and code for later use Data Structure: - S_Code, S_Name: State code and name - D_Code, District: District code and name - T_Code, Town: Town code and name - IV_Unit_No, Block_No: Investigation unit and block identifiers - No_of_Households: Number of households in each block This creates the foundation dataset for cluster sampling analysis. Code # ============================================================================= # STEP 1: DATA DOWNLOAD AND INITIAL PROCESSING # ============================================================================= print(&quot;=&quot;*80) print(&quot;STEP 1: DOWNLOADING AND LOADING DATA&quot;) print(&quot;=&quot;*80) url = &quot;https://mospi.gov.in/sites/default/files/publication_reports/UFS/UFS_30_Goa7112023.xlsx&quot; filename = generate_random_filename() folder_path = &quot;states&quot; # Download the Excel file download_file(url, folder_path=folder_path, filename=filename) # Load and process the Excel file filepath = os.path.join(folder_path, filename) df = pd.read_excel(filepath) print(f&quot;\\nInitial data shape: {df.shape}&quot;) print(f&quot;Initial columns: {list(df.columns)}&quot;) # Remove first 2 rows (likely headers) and limit to first 10 columns df = df.iloc[2:] df = df.iloc[:, :10] # Assign meaningful column names new_column_names = [&#39;S_Code&#39;, &#39;S_Name&#39;, &#39;D_Code&#39;, &#39;District&#39;, &#39;T_Code&#39;, &#39;Town&#39;, &#39;Code&#39;, &#39;IV_Unit_No&#39;, &#39;Block_No&#39;, &#39;No_of_Households&#39;] df.columns = new_column_names # Extract state information state_name = df.iloc[0, 1] state_code = df.iloc[0, 0] print(f&quot;\\n State Name: {state_name}&quot;) print(f&quot; State Code: {state_code}&quot;) print(f&quot;Processed data shape: {df.shape}&quot;) print(f&quot;\\nSample of processed data:&quot;) print(df.head()) ️ State Name: Goa ️ State Code: 30  Processed data shape: (1592, 10) Preprocessed data set: S_Code S_Name D_Code District T_Code Town IV_Unit_No Block_No No_of_Households 30 Goa 01 North Goa 001 Aldona 17 0001 63 30 Goa 01 North Goa 001 Aldona 17 0001 69 30 Goa 01 North Goa 001 Aldona 17 0001 83 30 Goa 01 North Goa 001 Aldona 17 0001 89 30 Goa 01 North Goa 001 Aldona 17 0001 90 District Selection and Filtering This step allows users to select specific districts for analysis: Process: 1. User Input: Prompts user to enter district codes separated by spaces 2. Data Filtering: Filters the main dataset to include only selected districts 3. Validation: Shows which districts are included in the filtered dataset Purpose: - Enables targeted analysis for specific geographical areas - Reduces dataset size for more focused sampling - Allows comparison between different district combinations Output: Filtered dataset containing only the selected districts with summary statistics. Code # ============================================================================= # STEP 2: DISTRICT SELECTION AND FILTERING # ============================================================================= print(&quot;\\n&quot; + &quot;=&quot;*80) print(&quot;STEP 2: DISTRICT SELECTION AND FILTERING&quot;) print(&quot;=&quot;*80) # Get user input for district codes D_Code_list = [&quot;01&quot;,&quot;02&quot;] print(f&quot;Selected district codes: {D_Code_list}&quot;) # Filter data for selected districts filtered_df = df[df[&#39;D_Code&#39;].isin(D_Code_list)] print(f&quot;Filtered data shape: {filtered_df.shape}&quot;) # Show unique districts in filtered data unique_districts = filtered_df[[&#39;D_Code&#39;, &#39;District&#39;]].drop_duplicates() print(f&quot;\\n Districts in filtered data:&quot;) display(unique_districts.to_string(index=False)) Selected district codes: ['01', '02'] Filtered data shape: (1592, 10) D_Code District 01 North Goa 02 South Goa Exclusion Logic This step implements quality control by removing Investigation Units (IV Units) with insufficient data for the sampling process Quality Criteria: - Threshold: IV Units with fewer than 20 blocks are considered insufficient for reliable sampling - Analysis Level: Examines each Town-IV Unit combination within districts Process: 1. Frequency Analysis: Counts blocks per IV Unit in each town 2. Threshold Application: Identifies IV Units with &lt;20 blocks 3. Exclusion Decision: Removes insufficient IV Units based on Excluder parameter 4. Data Cleaning: Creates filtered dataset with only sufficient IV Units Output: Clean dataset with only statistically viable IV Units for cluster sampling. Code # ============================================================================= # STEP 3: EXCLUSION LOGIC - REMOVE IV UNITS WITH &lt;20 BLOCKS # ============================================================================= print(&quot;\\n&quot; + &quot;=&quot;*80) print(&quot;STEP 3: APPLYING EXCLUSION LOGIC&quot;) print(&quot;=&quot;*80) # Set exclusion parameter (1 to enable exclusion, 0 to disable) Excluder = 1 # Set to 1 to enable exclusion, 0 to disable excluded_combinations_by_district = {} print(&quot; Analyzing IV Units by district...&quot;) for district_code, group in filtered_df.groupby(&#39;D_Code&#39;): print(f&quot;\\n Processing District: {district_code}&quot;) # Count frequency of each T_Code + IV_Unit_No combination er = group.groupby([&#39;T_Code&#39;, &#39;IV_Unit_No&#39;]).size().reset_index(name=&#39;Frequency&#39;) print(f&quot;  Total T_Code + IV_Unit_No combinations: {len(er)}&quot;) # Find combinations with less than 20 blocks excluded_combinations = er[er[&#39;Frequency&#39;] &lt; 20][[&#39;T_Code&#39;, &#39;IV_Unit_No&#39;]] print(f&quot; ❌ Combinations with &lt;20 blocks: {len(excluded_combinations)}&quot;) # Skip if all combinations would be excluded and Excluder is 0 if len(excluded_combinations) == er.shape[0] and Excluder == 0: print(f&quot; ⚠️ All combinations would be excluded, skipping district {district_code}&quot;) continue if not excluded_combinations.empty: excluded_combinations_by_district[district_code] = [tuple(x) for x in excluded_combinations.to_records(index=False)] print(f&quot;  Excluded combinations: {excluded_combinations_by_district[district_code]}&quot;) # Create a set of all excluded combinations for filtering excluded_combinations = { (d_code, t_code, iv_unit_no) for d_code, combinations in excluded_combinations_by_district.items() for t_code, iv_unit_no in combinations } print(f&quot;\\n Total excluded combinations across all districts: {len(excluded_combinations)}&quot;) # Apply exclusion filter filtered_df1 = filtered_df[ ~filtered_df.set_index([&#39;D_Code&#39;, &#39;T_Code&#39;, &#39;IV_Unit_No&#39;]).index.isin(excluded_combinations) ].reset_index(drop=True) print(f&quot; Data shape after exclusions: {filtered_df1.shape}&quot;) print(f&quot; Rows removed: {len(filtered_df) - len(filtered_df1)}&quot;)  Analyzing IV Units by district…  Processing District: 01  Total T_Code + IV_Unit_No combinations: 56 ❌ Combinations with &lt;20 blocks: 42  Excluded combinations: (‘001’, ‘0001’), (‘002’, ‘0001’), (‘007’, ‘0001’), (‘008’, ‘0001’), (‘010’, ‘0001’), (‘011’, ‘0001’), (‘012’, ‘0001’), (‘013’, ‘0001’), (‘014’, ‘0002’), (‘014’, ‘0003’), (‘015’, ‘0001’), (‘016’, ‘0001’), (‘016’, ‘0002’), (‘016’, ‘0003’), (‘016’, ‘0005’), (‘017’, ‘0001’), (‘019’, ‘0001’), (‘021’, ‘0001’), (‘022’, ‘0001’), (‘023’, ‘0001’), (‘024’, ‘0001’), (‘025’, ‘0001’), (‘026’, ‘0001’), (‘027’, ‘0001’), (‘028’, ‘0001’), (‘029’, ‘0001’), (‘030’, ‘0001’), (‘031’, ‘0001’), (‘032’, ‘0001’), (‘033’, ‘0001’), (‘034’, ‘0001’), (‘035’, ‘0001’), (‘038’, ‘0001’), (‘039’, ‘0001’), (‘040’, ‘0001’), (‘042’, ‘0001’), (‘046’, ‘0001’), (‘048’, ‘0001’), (‘049’, ‘0001’), (‘050’, ‘0001’), (‘051’, ‘0001’), (‘052’, ‘0001’)  Processing District: 02  Total T_Code + IV_Unit_No combinations: 29 ❌ Combinations with &lt;20 blocks: 11  Excluded combinations: (‘001’, ‘0001’), (‘002’, ‘0001’), (‘005’, ‘0001’), (‘009’, ‘0002’), (‘010’, ‘0002’), (‘011’, ‘0001’), (‘014’, ‘0001’), (‘015’, ‘0001’), (‘016’, ‘0001’), (‘017’, ‘0001’), (‘018’, ‘0001’)  Total excluded combinations across all districts: 53  Data shape after exclusions: (890, 10)  Rows removed: 702 Cluster Calculation and Proportional Allocation This step implements the core statistical methodology for cluster sampling: Sampling Strategy: 1. IV unit Count: Counts unique IV Units per district 2. Proportional Allocation: Distributes target clusters based on district size with respect to the number of IV units Key Calculations: - District Proportion = IV Units in District / Total IV Units - Allocated Clusters = Target Clusters × District Proportion - Minimum Allocation: Each district gets at least 1 cluster (+1 adjustment) User Input: Total number of clusters to be selected for the survey Output: District-wise cluster allocation plan with verification totals. Code # ============================================================================= # STEP 4: CLUSTER CALCULATION AND ALLOCATION # ============================================================================= print(&quot;\\n&quot; + &quot;=&quot;*80) print(&quot;STEP 4: CLUSTER CALCULATION AND ALLOCATION&quot;) print(&quot;=&quot;*80) # Count unique IV units per district and town g = filtered_df1.iloc[:, :8].groupby(by=[&quot;D_Code&quot;, &quot;T_Code&quot;])[[&#39;IV_Unit_No&#39;]].nunique() print(&quot; IV Units per District-Town combination:&quot;) print(g.head(10)) # Sum up total clusters per district unique_iv_unit_counts = g.groupby(by=[&quot;D_Code&quot;]).sum() print(f&quot;\\n Total IV Units per district:&quot;) print(unique_iv_unit_counts) # Calculate proportions unique_iv_unit_counts_proportion = unique_iv_unit_counts / unique_iv_unit_counts.sum() unique_iv_unit_counts[&#39;Proportion&#39;] = unique_iv_unit_counts_proportion print(f&quot;\\n District proportions:&quot;) print(unique_iv_unit_counts[[&#39;IV_Unit_No&#39;, &#39;Proportion&#39;]]) # Get total number of clusters from user num_clusters = int(input(&quot;Enter the total number of clusters to select: &quot;)) print(f&quot; Target total clusters: {num_clusters}&quot;) # Allocate clusters proportionally to each district unique_iv_unit_counts[&#39;No_of_Cluster&#39;] = (unique_iv_unit_counts_proportion * num_clusters) unique_iv_unit_counts[&#39;No_of_Cluster&#39;] = unique_iv_unit_counts[&#39;No_of_Cluster&#39;].apply(int) + 1 print(f&quot;\\n Cluster allocation per district:&quot;) print(unique_iv_unit_counts[[&#39;IV_Unit_No&#39;, &#39;Proportion&#39;, &#39;No_of_Cluster&#39;]]) # Add district names to results district_names = df[[&#39;D_Code&#39;, &#39;District&#39;]].drop_duplicates() result = pd.merge(unique_iv_unit_counts, district_names, on=&#39;D_Code&#39;, how=&#39;left&#39;) result = result[[&#39;D_Code&#39;, &#39;District&#39;, &#39;IV_Unit_No&#39;, &#39;Proportion&#39;, &#39;No_of_Cluster&#39;]] print(f&quot;\\n Final cluster allocation:&quot;) print(result.to_string(index=False)) # Verify total allocated clusters total_allocated = result[&#39;No_of_Cluster&#39;].sum() print(f&quot;\\n✅ Total clusters allocated: {total_allocated}&quot;) print(f&quot; Target clusters: {num_clusters}&quot;) print(f&quot; Difference: {total_allocated - num_clusters}&quot;)  Total IV Units per district D_Code IV_Unit_No 01 14 02 18  District proportions D_Code IV_Unit_No Proportion 01 14 0.4375 02 18 0.5625  Target total clusters: 131  Final cluster allocation D_Code District IV_Unit_No Proportion No_of_Cluster 01 North Goa 14 0.4375 58 02 South Goa 18 0.5625 74 ✅ Total clusters allocated: 132  Target clusters: 131  Difference: 1 Utility Functions for Report Generation This section defines helper functions for creating professional output reports: Excel Generation Functions: - extract_clusters_to_excel(): Creates multi-sheet Excel workbooks with one sheet per district - Formats data with proper headers and structure PDF Generation Functions: - add_text_page(): Adds formatted text content to PDF documents - create_table_pdf(): Generates professional tables with styling - Handles page breaks and font formatting Data Formatting Functions: - format_excluded_combinations(): Creates readable summaries of excluded IV Units - Provides clear documentation of data quality decisions Purpose: These functions enable automated generation of professional reports for survey planning and documentation, ensuring consistent formatting and comprehensive coverage of sampling decisions. Code # ============================================================================= # UTILITY FUNCTIONS FOR EXCEL AND PDF GENERATION # ============================================================================= def extract_clusters_to_excel(selected_clusters, output_file): &quot;&quot;&quot;Create Excel file with separate sheets for each district&quot;&quot;&quot; workbook = Workbook() workbook.remove(workbook.active) # Remove default sheet for district_code, df in selected_clusters.items(): if not df.empty: sheet_name = f&quot;District_{district_code}&quot; worksheet = workbook.create_sheet(title=sheet_name) # Add headers worksheet.append(list(df.columns)) # Add data for row in df.values.tolist(): worksheet.append(row) workbook.save(output_file) print(f&quot;✅ Excel file created: {output_file}&quot;) def add_text_page(pdf_canvas, text): &quot;&quot;&quot;Add text content to PDF canvas&quot;&quot;&quot; pdf_canvas.setFont(&quot;CourierNew&quot;, 12) text_lines = text.split(&#39;\\n&#39;) y_position = 800 for line in text_lines: if y_position &lt; 50: pdf_canvas.showPage() pdf_canvas.setFont(&quot;CourierNew&quot;, 12) y_position = 800 pdf_canvas.drawString(72, y_position, line) y_position -= 14 pdf_canvas.showPage() def create_table_pdf(df, output_path): &quot;&quot;&quot;Create PDF with table from DataFrame&quot;&quot;&quot; doc = SimpleDocTemplate(output_path, pagesize=A4) table_data = [df.columns.tolist()] + df.values.tolist() table = Table(table_data) style = TableStyle([ (&#39;BACKGROUND&#39;, (0, 0), (-1, 0), colors.grey), (&#39;TEXTCOLOR&#39;, (0, 0), (-1, 0), colors.whitesmoke), (&#39;ALIGN&#39;, (0, 0), (-1, -1), &#39;CENTER&#39;), (&#39;FONTNAME&#39;, (0, 0), (-1, 0), &#39;CourierNew&#39;), (&#39;FONTNAME&#39;, (0, 1), (-1, -1), &#39;CourierNew&#39;), (&#39;BOTTOMPADDING&#39;, (0, 0), (-1, 0), 12), (&#39;BACKGROUND&#39;, (0, 1), (-1, -1), colors.white), (&#39;GRID&#39;, (0, 0), (-1, -1), 1, colors.black), ]) table.setStyle(style) doc.build([table]) def format_excluded_combinations(excluded_dict): &quot;&quot;&quot;Format excluded combinations for display&quot;&quot;&quot; if not excluded_dict: return &quot;No IV Units were excluded based on the frequency criteria.\\n&quot; formatted_text = &quot;District wise excluded IV Units:\\n\\n&quot; for district, exclusions in excluded_dict.items(): formatted_text += f&quot;District Code: {district}\\n&quot; formatted_text += &quot;Town_Code || IV_Unit_No\\n&quot; formatted_text += &quot;-&quot; * 25 + &quot;\\n&quot; for town_code, iv_unit_no in exclusions: formatted_text += f&quot;{town_code:&lt;10} || {iv_unit_no}\\n&quot; formatted_text += &quot;\\n&quot; return formatted_text  RESULT SUMMARY State Name: Goa State Code: 30 District Codes: 01, 02 Total Clusters Requested: 131 Total Clusters Allocated: 132 Exclusion Applied: Yes  Cluster Allocation by District D_Code District IV_Unit_No Proportion No_of_Cluster 01 North Goa 14 0.4375 58 02 South Goa 18 0.5625 74 Result Summary and Sampling Preparation This step creates a comprehensive summary of the sampling plan and prepares for execution: Summary Components: 1. Metadata: State name, state code, selected districts 2. Allocation Summary: Target vs. allocated clusters 3. Quality Control: Documentation of exclusions applied 4. District Breakdown: Detailed allocation table Iteration Setup: - Multiple Samples: Allows generation of multiple independent samples - Reproducibility: Each iteration creates a different random sample Code # ============================================================================= # STEP 5: PREPARE RESULT SUMMARY # ============================================================================= print(&quot;\\n&quot; + &quot;=&quot;*80) print(&quot;STEP 5: PREPARING RESULT SUMMARY&quot;) print(&quot;=&quot;*80) result_string = [] result_string.append(&#39;\\n\\nRESULT SUMMARY&#39;) result_string.append(f&#39;State Name: {df.iloc[0, 1]}&#39;) result_string.append(f&#39;State Code: {df.iloc[0, 0]}&#39;) result_string.append(f&#39;District Codes: {&quot; &quot;.join(D_Code_list)}&#39;) result_string.append(f&#39;Total Clusters Requested: {num_clusters}&#39;) result_string.append(f&#39;Total Clusters Allocated: {total_allocated}&#39;) result_string.append(f&#39;Exclusion Applied: {&quot;Yes&quot; if Excluder else &quot;No&quot;}&#39;) result_string.append(&#39;\\n&#39; + &#39;-&#39;*55) result_string.append(result.to_string(index=False)) final_result = &#39;\\n&#39;.join(result_string) print(final_result) # Get number of sample iterations from user multiplier = int(input(&quot;Enter number of sample iterations to generate (usually 1): &quot;) or &quot;1&quot;) print(f&quot; Will generate {multiplier} independent sample(s)&quot;) Random Cluster Sampling Implementation This is the core sampling execution step that implements probability-based cluster selection: Two-Stage Sampling Process: Stage 1: IV Unit Selection - Random selection of IV Units from each district - Uses allocated cluster counts from Step 4 - Implements replacement logic when needed Stage 2: Block Selection - Within selected IV Units, randomly samples UFS blocks - Ensures actual sample size matches allocation Sampling Features: - Without Replacement: Preferred method when sufficient IV Units available - With Replacement: Used when target clusters exceed available IV Units - Proportional Allocation: Maintains district-level representativeness - Frequency Tracking: Documents how often each IV Unit is selected Output: Dictionary of selected clusters organized by district, ready for geocoding and reporting. Code # ============================================================================= # STEP 6: CLUSTER SAMPLING AND REPORT GENERATION # ============================================================================= print(&quot;\\n&quot; + &quot;=&quot;*80) print(&quot;STEP 6: CLUSTER SAMPLING AND REPORT GENERATION&quot;) print(&quot;=&quot;*80) for z in range(multiplier): print(f&quot;\\n Processing iteration {z+1}/{multiplier}&quot;) selected_clusters = {} # Sample clusters for each district for district_code, row in unique_iv_unit_counts.iterrows(): print(f&quot;\\n Sampling for District: {district_code}&quot;) num_clusters_for_district = int(row[&#39;No_of_Cluster&#39;]) num_iv_units = int(row[&#39;IV_Unit_No&#39;]) print(f&quot;  Target clusters: {num_clusters_for_district}&quot;) print(f&quot;  Available IV units: {num_iv_units}&quot;) # Get data for this district district_df = filtered_df1[filtered_df1[&#39;D_Code&#39;] == district_code] print(f&quot;  District data rows: {len(district_df)}&quot;) # Get unique IV units in this district unique_df = district_df.drop_duplicates(subset=[&#39;T_Code&#39;, &#39;IV_Unit_No&#39;])[[&#39;T_Code&#39;, &#39;IV_Unit_No&#39;]] print(f&quot;  Unique IV units available: {len(unique_df)}&quot;) # Sample IV units (with or without replacement) if num_iv_units &gt;= num_clusters_for_district: sampled_df = unique_df.sample(n=num_clusters_for_district, replace=False) print(f&quot; ✅ Sampled {num_clusters_for_district} IV units without replacement&quot;) else: sampled_df = pd.concat([ unique_df.sample(n=unique_df.shape[0], replace=False), unique_df.sample(n=num_clusters_for_district - unique_df.shape[0], replace=True) ]) print(f&quot; ⚠️ Sampled with replacement (needed {num_clusters_for_district}, had {num_iv_units})&quot;) # Count frequency of selected IV units frequency_df = sampled_df.groupby([&#39;T_Code&#39;, &#39;IV_Unit_No&#39;]).size().reset_index(name=&#39;Frequency&#39;) print(f&quot;  IV unit frequency distribution:&quot;) print(f&quot; {frequency_df.to_string(index=False)}&quot;) # Sample UFS blocks from selected IV units UFS_samples = [] for _, row2 in frequency_df.iterrows(): t_code = row2[&#39;T_Code&#39;] iv_unit_no = row2[&#39;IV_Unit_No&#39;] freq = row2[&#39;Frequency&#39;] # Get all blocks for this IV unit available_blocks = district_df[(district_df[&#39;T_Code&#39;] == t_code) &amp; (district_df[&#39;IV_Unit_No&#39;] == iv_unit_no)] N = available_blocks.shape[0] # Sample blocks (cannot sample more than available) if N &lt; freq: UFS_sample = available_blocks.sample(n=N, replace=False) print(f&quot; ⚠️ Town {t_code}, IV {iv_unit_no}: sampled {N} blocks (needed {freq})&quot;) else: UFS_sample = available_blocks.sample(n=freq, replace=False) print(f&quot; ✅ Town {t_code}, IV {iv_unit_no}: sampled {freq} blocks from {N} available&quot;) UFS_samples.append(UFS_sample) # Combine all samples for this district selected_clusters[district_code] = pd.concat(UFS_samples, ignore_index=True) print(f&quot;  Total selected blocks for district: {len(selected_clusters[district_code])}&quot;) # Show summary of this iteration print(f&quot;\\n✅ ITERATION {z+1} SAMPLING COMPLETE&quot;) print(f&quot; Summary of selected clusters:&quot;) for district_code, df_dist in selected_clusters.items(): print(f&quot; District {district_code}: {len(df_dist)} clusters selected&quot;)  Sampling Iteration Results Number of iterations: 1  District 01 — North Goa  Target clusters: 58  Available IV units: 14  District data rows: 370  Unique IV units available: 14 ⚠️ Sampled with replacement (needed 58, had 14)  IV Unit Frequency Distribution (Result of SRS) T_Code IV_Unit_No Frequency 003 0001 1 004 0001 3 005 0001 2 006 0001 7 009 0001 5 014 0001 4 016 0004 5 018 0001 7 020 0001 5 036 0001 2 037 0001 3 041 0001 8 043 0001 4 047 0001 2 ✅ Block Sampling Summary - Town 003, IV 0001 → 1 / 20 blocks - Town 004, IV 0001 → 3 / 23 blocks - Town 005, IV 0001 → 2 / 28 blocks - Town 006, IV 0001 → 7 / 20 blocks - Town 009, IV 0001 → 5 / 23 blocks - Town 014, IV 0001 → 4 / 31 blocks - Town 016, IV 0004 → 5 / 32 blocks - Town 018, IV 0001 → 7 / 39 blocks - Town 020, IV 0001 → 5 / 29 blocks - Town 036, IV 0001 → 2 / 30 blocks - Town 037, IV 0001 → 3 / 21 blocks - Town 041, IV 0001 → 8 / 29 blocks - Town 043, IV 0001 → 4 / 25 blocks - Town 047, IV 0001 → 2 / 20 blocks  Total selected blocks: 58  District 02 — South Goa  Target clusters: 74  Available IV units: 18  District data rows: 520  Unique IV units available: 18 ⚠️ Sampled with replacement (needed 74, had 18)  IV Unit Frequency Distribution (Result of SRS) T_Code IV_Unit_No Frequency 003 0001 3 004 0001 4 006 0001 7 007 0001 3 008 0001 4 009 0001 3 009 0003 6 009 0004 4 009 0005 2 009 0006 4 010 0001 5 010 0003 5 010 0004 7 010 0005 1 012 0001 5 013 0001 3 019 0001 5 021 0001 3 ✅ Block Sampling Summary - Town 003, IV 0001 → 3 / 23 blocks - Town 004, IV 0001 → 4 / 21 blocks - Town 006, IV 0001 → 7 / 25 blocks - Town 007, IV 0001 → 3 / 31 blocks - Town 008, IV 0001 → 4 / 24 blocks - Town 009, IV 0001 → 3 / 32 blocks - Town 009, IV 0003 → 6 / 25 blocks - Town 009, IV 0004 → 4 / 46 blocks - Town 009, IV 0005 → 2 / 29 blocks - Town 009, IV 0006 → 4 / 33 blocks - Town 010, IV 0001 → 5 / 32 blocks - Town 010, IV 0003 → 5 / 24 blocks - Town 010, IV 0004 → 7 / 38 blocks - Town 010, IV 0005 → 1 / 32 blocks - Town 012, IV 0001 → 5 / 22 blocks - Town 013, IV 0001 → 3 / 30 blocks - Town 019, IV 0001 → 5 / 29 blocks - Town 021, IV 0001 → 3 / 24 blocks  Total selected blocks: 74 Geographic Coordinate Assignment (Geocoding) This step adds spatial coordinates to enable mapping and geographic analysis: Geocoding Process: 1. Location Query: Constructs queries using “Town, District, State” format 2. Service Provider: Uses ArcGIS geocoding service via geopy library 3. Coordinate Extraction: Retrieves latitude and longitude for each location 4. Error Handling: Manages failed geocoding attempts gracefully Data Enhancement: - Spatial Coordinates: Adds Latitude and Longitude columns - Quality Reporting: Tracks successful vs. failed geocoding attempts - Coverage Analysis: Reports geocoding success rates by district Code # ============================================================================= # STEP 7: GEOCODING # ============================================================================= print(f&quot;\\n STEP 7: GEOCODING SELECTED LOCATIONS&quot;) print(&quot;-&quot; * 50) locator = geopy.geocoders.ArcGIS(user_agent=&quot;mygeocoder&quot;) for district_code, df_dist in selected_clusters.items(): if not df_dist.empty: print(f&quot;\\n Geocoding for District {district_code}...&quot;) for index, row in df_dist.iterrows(): try: # Create location query using town, district, and state location_query = f&quot;{row[&#39;Town&#39;]}, {row[&#39;District&#39;]}, {state_name}&quot; location = locator.geocode(location_query) if location: df_dist.loc[index, &#39;Latitude&#39;] = location.latitude df_dist.loc[index, &#39;Longitude&#39;] = location.longitude print(f&quot; ✅ {row[&#39;Town&#39;]}: ({location.latitude:.4f}, {location.longitude:.4f})&quot;) else: df_dist.loc[index, &#39;Latitude&#39;] = None df_dist.loc[index, &#39;Longitude&#39;] = None print(f&quot; ❌ {row[&#39;Town&#39;]}: Location not found&quot;) except Exception as e: print(f&quot; ❌ Error geocoding {row[&#39;Town&#39;]}: {e}&quot;) df_dist.loc[index, &#39;Latitude&#39;] = None df_dist.loc[index, &#39;Longitude&#39;] = None # Show geocoding summary for this district geocoded_count = df_dist[&#39;Latitude&#39;].notna().sum() total_count = len(df_dist) print(f&quot;  Geocoded {geocoded_count}/{total_count} locations ({geocoded_count/total_count*100:.1f}%)&quot;) Output Generation and Final Documentation This final step generates comprehensive outputs and provides project completion summary: Output Files Generated: 1. Excel Reports: Multi-sheet workbooks with one sheet per district - Contains all selected cluster details - Includes geographic coordinates - Formatted for field use Directory Structure: Creates organized folder system map/: Reserved for mapping outputs temp/: Temporary processing files GIS/: Geospatial data files Quality Assurance: - Sample Verification: Displays sample of selected clusters - Count Validation: Verifies cluster counts match allocation - Coordinate Check: Shows geocoding success rates Final Summary: - Iteration Tracking: Documents number of independent samples generated - File Naming: Uses standardized naming convention with state identifiers - Performance Metrics: Reports total clusters and processing statistics Deliverables: Ready-to-use cluster sampling results for urban survey implementation, complete with coordinates and detailed documentation for field teams. Code # ============================================================================= # STEP 8: GENERATE OUTPUT FILES # ============================================================================= print(f&quot;\\n STEP 8: GENERATING OUTPUT FILES&quot;) print(&quot;-&quot; * 50) # Generate Excel output excel_filename = f&quot;Urban Report[EXCEL-{z+1}]-{state_name}_{state_code}.xlsx&quot; extract_clusters_to_excel(selected_clusters, output_file=excel_filename) # Create directories if they don&#39;t exist os.makedirs(&quot;map&quot;, exist_ok=True) os.makedirs(&quot;temp&quot;, exist_ok=True) os.makedirs(&quot;GIS&quot;, exist_ok=True) print(f&quot;\\n✅ PROCESSING COMPLETE FOR ITERATION {z+1}&quot;) print(f&quot; Summary of selected clusters:&quot;) for district_code, df_dist in selected_clusters.items(): print(f&quot; District {district_code}: {len(df_dist)} clusters selected&quot;) # Display first few selected clusters for verification print(f&quot;\\n Sample of selected clusters:&quot;) sample_df = pd.concat(selected_clusters.values()).head(10) print(sample_df[[&#39;District&#39;, &#39;Town&#39;, &#39;IV_Unit_No&#39;, &#39;Block_No&#39;, &#39;Latitude&#39;, &#39;Longitude&#39;]].to_string(index=False)) print(f&quot;\\n ALL ITERATIONS COMPLETED!&quot;) print(f&quot; Output files generated with prefix: Urban Report[EXCEL]-{state_name}_{state_code}&quot;) print(f&quot; Total sample iterations: {multiplier}&quot;) # Final summary total_clusters_generated = sum(len(df_dist) for df_dist in selected_clusters.values()) print(f&quot; Clusters per iteration: ~{total_clusters_generated}&quot;) print(f&quot; Total clusters across all iterations: ~{total_clusters_generated * multiplier}&quot;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
