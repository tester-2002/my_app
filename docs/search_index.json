[["cluster-selection-in-urban-areas.html", "Cluster selection in Urban areas Import Libraries and Utility Functions Data Download and Initial Processing District Selection and Filtering Exclusion Logic Cluster Calculation and Proportional Allocation Utility Functions for Report Generation Result Summary and Sampling Preparation Random Cluster Sampling Implementation Geographic Coordinate Assignment (Geocoding) Output Generation and Final Documentation", " Cluster selection in Urban areas Program Flow chart Code knitr::include_graphics(&quot;flow-chart.svg&quot;) Code # Install Python packages via pip system(&quot;pip install requests pandas geopy openpyxl geopandas matplotlib numpy reportlab PyPDF2&quot;) # Download files from Google Drive using gdown system(&quot;gdown https://drive.google.com/uc?id=1BQnzVmLHCfw84z-RnfWbdgcpNIBNgKWc&quot;) system(&quot;gdown https://drive.google.com/uc?id=18L5b_ya_YxoD7-PCfw8ftzeXU0jh6BIy&quot;) # Make directory dir.create(&quot;GIS map temp&quot;, showWarnings = FALSE) # Unzip file unzip(&quot;district_boundries.zip&quot;, exdir = &quot;GIS&quot;) # Remove zip file unlink(&quot;district_boundries.zip&quot;) # Remove folder unlink(&quot;sample_data&quot;, recursive = TRUE) Import Libraries and Utility Functions This section imports all necessary libraries for data processing, file operations, geographic analysis, visualization, and PDF generation. It also includes utility functions for: File Download: Download files from URLs with error handling and progress tracking Random Filename Generation: Create unique filenames to avoid conflicts during file operations Key Libraries: - pandas, numpy: Data manipulation and analysis - geopandas, geopy: Geographic data processing - matplotlib: Data visualization - reportlab, PyPDF2: PDF generation and manipulation - requests: HTTP requests for file downloads - openpyxl: Excel file operations Code import requests import os import random import string import pandas as pd import geopy from openpyxl import Workbook import geopandas as gpd import matplotlib.pyplot as plt import numpy as np from collections import Counter import warnings from reportlab.lib import colors from reportlab.lib.pagesizes import A4 from reportlab.lib.units import inch from reportlab.pdfgen import canvas from reportlab.pdfbase import pdfmetrics from reportlab.pdfbase.ttfonts import TTFont from reportlab.platypus import Table, TableStyle, SimpleDocTemplate from PyPDF2 import PdfWriter, PdfReader from IPython.display import display # Suppress specific warnings to keep output clean warnings.filterwarnings(&#39;ignore&#39;) def download_file(url, folder_path, filename): &quot;&quot;&quot; Download a file from URL and save it to specified folder Returns: filepath if successful, None if failed &quot;&quot;&quot; try: # Create directory if it doesn&#39;t exist if not os.path.exists(folder_path): os.makedirs(folder_path) print(f&quot;✓ Created directory: {folder_path}&quot;) # Download file with streaming to handle large files response = requests.get(url, stream=True) response.raise_for_status() filepath = os.path.join(folder_path, filename) with open(filepath, &#39;wb&#39;) as file: for chunk in response.iter_content(chunk_size=8192): file.write(chunk) print(f&quot;✓ File downloaded successfully: {filepath}&quot;) return filepath except requests.exceptions.RequestException as e: print(f&quot;✗ Error downloading file: {e}&quot;) return None def generate_random_filename(length=10, extension=&quot;.xlsx&quot;): &quot;&quot;&quot;Generate a random filename to avoid conflicts&quot;&quot;&quot; characters = string.ascii_letters + string.digits random_filename = &#39;&#39;.join(random.choice(characters) for _ in range(length)) + extension return random_filename Data Download and Initial Processing This step handles the initial data acquisition and preprocessing: Key Operations: 1. Download Data: Downloads UFS (Urban Frame Survey) data from MOSPI website for Goa state 2. Load Excel File: Reads the downloaded Excel file into a pandas DataFrame 3. Clean Headers: Removes metadata rows and assigns meaningful column names 4. Extract State Info: Captures state name and code for later use Data Structure: - S_Code, S_Name: State code and name - D_Code, District: District code and name - T_Code, Town: Town code and name - IV_Unit_No, Block_No: Investigation unit and block identifiers - No_of_Households: Number of households in each block This creates the foundation dataset for cluster sampling analysis. Code # ============================================================================= # STEP 1: DATA DOWNLOAD AND INITIAL PROCESSING # ============================================================================= print(&quot;=&quot;*80) print(&quot;STEP 1: DOWNLOADING AND LOADING DATA&quot;) print(&quot;=&quot;*80) url = &quot;https://mospi.gov.in/sites/default/files/publication_reports/UFS/UFS_30_Goa7112023.xlsx&quot; filename = generate_random_filename() folder_path = &quot;states&quot; # Download the Excel file download_file(url, folder_path=folder_path, filename=filename) # Load and process the Excel file filepath = os.path.join(folder_path, filename) df = pd.read_excel(filepath) print(f&quot;\\nInitial data shape: {df.shape}&quot;) print(f&quot;Initial columns: {list(df.columns)}&quot;) # Remove first 2 rows (likely headers) and limit to first 10 columns df = df.iloc[2:] df = df.iloc[:, :10] # Assign meaningful column names new_column_names = [&#39;S_Code&#39;, &#39;S_Name&#39;, &#39;D_Code&#39;, &#39;District&#39;, &#39;T_Code&#39;, &#39;Town&#39;, &#39;Code&#39;, &#39;IV_Unit_No&#39;, &#39;Block_No&#39;, &#39;No_of_Households&#39;] df.columns = new_column_names # Extract state information state_name = df.iloc[0, 1] state_code = df.iloc[0, 0] print(f&quot;\\n State Name: {state_name}&quot;) print(f&quot; State Code: {state_code}&quot;) print(f&quot;Processed data shape: {df.shape}&quot;) print(f&quot;\\nSample of processed data:&quot;) print(df.head()) ️ State Name: Goa ️ State Code: 30  Processed data shape: (1592, 10) Preprocessed data set: S_Code S_Name D_Code District T_Code Town IV_Unit_No Block_No No_of_Households 30 Goa 01 North Goa 001 Aldona 17 0001 63 30 Goa 01 North Goa 001 Aldona 17 0001 69 30 Goa 01 North Goa 001 Aldona 17 0001 83 30 Goa 01 North Goa 001 Aldona 17 0001 89 30 Goa 01 North Goa 001 Aldona 17 0001 90 District Selection and Filtering This step allows users to select specific districts for analysis: Process: 1. User Input: Prompts user to enter district codes separated by spaces 2. Data Filtering: Filters the main dataset to include only selected districts 3. Validation: Shows which districts are included in the filtered dataset Purpose: - Enables targeted analysis for specific geographical areas - Reduces dataset size for more focused sampling - Allows comparison between different district combinations Output: Filtered dataset containing only the selected districts with summary statistics. Code # ============================================================================= # STEP 2: DISTRICT SELECTION AND FILTERING # ============================================================================= print(&quot;\\n&quot; + &quot;=&quot;*80) print(&quot;STEP 2: DISTRICT SELECTION AND FILTERING&quot;) print(&quot;=&quot;*80) # Get user input for district codes D_Code_list = [&quot;01&quot;,&quot;02&quot;] print(f&quot;Selected district codes: {D_Code_list}&quot;) # Filter data for selected districts filtered_df = df[df[&#39;D_Code&#39;].isin(D_Code_list)] print(f&quot;Filtered data shape: {filtered_df.shape}&quot;) # Show unique districts in filtered data unique_districts = filtered_df[[&#39;D_Code&#39;, &#39;District&#39;]].drop_duplicates() print(f&quot;\\n Districts in filtered data:&quot;) display(unique_districts.to_string(index=False)) Selected district codes: ['01', '02'] Filtered data shape: (1592, 10) D_Code District 01 North Goa 02 South Goa Exclusion Logic This step implements quality control by removing Investigation Units (IV Units) with insufficient data for the sampling process Quality Criteria: - Threshold: IV Units with fewer than 20 blocks are considered insufficient for reliable sampling - Analysis Level: Examines each Town-IV Unit combination within districts Process: 1. Frequency Analysis: Counts blocks per IV Unit in each town 2. Threshold Application: Identifies IV Units with &lt;20 blocks 3. Exclusion Decision: Removes insufficient IV Units based on Excluder parameter 4. Data Cleaning: Creates filtered dataset with only sufficient IV Units Output: Clean dataset with only statistically viable IV Units for cluster sampling. Code # ============================================================================= # STEP 3: EXCLUSION LOGIC - REMOVE IV UNITS WITH &lt;20 BLOCKS # ============================================================================= print(&quot;\\n&quot; + &quot;=&quot;*80) print(&quot;STEP 3: APPLYING EXCLUSION LOGIC&quot;) print(&quot;=&quot;*80) # Set exclusion parameter (1 to enable exclusion, 0 to disable) Excluder = 1 # Set to 1 to enable exclusion, 0 to disable excluded_combinations_by_district = {} print(&quot; Analyzing IV Units by district...&quot;) for district_code, group in filtered_df.groupby(&#39;D_Code&#39;): print(f&quot;\\n Processing District: {district_code}&quot;) # Count frequency of each T_Code + IV_Unit_No combination er = group.groupby([&#39;T_Code&#39;, &#39;IV_Unit_No&#39;]).size().reset_index(name=&#39;Frequency&#39;) print(f&quot;  Total T_Code + IV_Unit_No combinations: {len(er)}&quot;) # Find combinations with less than 20 blocks excluded_combinations = er[er[&#39;Frequency&#39;] &lt; 20][[&#39;T_Code&#39;, &#39;IV_Unit_No&#39;]] print(f&quot; ❌ Combinations with &lt;20 blocks: {len(excluded_combinations)}&quot;) # Skip if all combinations would be excluded and Excluder is 0 if len(excluded_combinations) == er.shape[0] and Excluder == 0: print(f&quot; ⚠️ All combinations would be excluded, skipping district {district_code}&quot;) continue if not excluded_combinations.empty: excluded_combinations_by_district[district_code] = [tuple(x) for x in excluded_combinations.to_records(index=False)] print(f&quot;  Excluded combinations: {excluded_combinations_by_district[district_code]}&quot;) # Create a set of all excluded combinations for filtering excluded_combinations = { (d_code, t_code, iv_unit_no) for d_code, combinations in excluded_combinations_by_district.items() for t_code, iv_unit_no in combinations } print(f&quot;\\n Total excluded combinations across all districts: {len(excluded_combinations)}&quot;) # Apply exclusion filter filtered_df1 = filtered_df[ ~filtered_df.set_index([&#39;D_Code&#39;, &#39;T_Code&#39;, &#39;IV_Unit_No&#39;]).index.isin(excluded_combinations) ].reset_index(drop=True) print(f&quot; Data shape after exclusions: {filtered_df1.shape}&quot;) print(f&quot; Rows removed: {len(filtered_df) - len(filtered_df1)}&quot;)  Analyzing IV Units by district…  Processing District: 01  Total T_Code + IV_Unit_No combinations: 56 ❌ Combinations with &lt;20 blocks: 42  Excluded combinations: (‘001’, ‘0001’), (‘002’, ‘0001’), (‘007’, ‘0001’), (‘008’, ‘0001’), (‘010’, ‘0001’), (‘011’, ‘0001’), (‘012’, ‘0001’), (‘013’, ‘0001’), (‘014’, ‘0002’), (‘014’, ‘0003’), (‘015’, ‘0001’), (‘016’, ‘0001’), (‘016’, ‘0002’), (‘016’, ‘0003’), (‘016’, ‘0005’), (‘017’, ‘0001’), (‘019’, ‘0001’), (‘021’, ‘0001’), (‘022’, ‘0001’), (‘023’, ‘0001’), (‘024’, ‘0001’), (‘025’, ‘0001’), (‘026’, ‘0001’), (‘027’, ‘0001’), (‘028’, ‘0001’), (‘029’, ‘0001’), (‘030’, ‘0001’), (‘031’, ‘0001’), (‘032’, ‘0001’), (‘033’, ‘0001’), (‘034’, ‘0001’), (‘035’, ‘0001’), (‘038’, ‘0001’), (‘039’, ‘0001’), (‘040’, ‘0001’), (‘042’, ‘0001’), (‘046’, ‘0001’), (‘048’, ‘0001’), (‘049’, ‘0001’), (‘050’, ‘0001’), (‘051’, ‘0001’), (‘052’, ‘0001’)  Processing District: 02  Total T_Code + IV_Unit_No combinations: 29 ❌ Combinations with &lt;20 blocks: 11  Excluded combinations: (‘001’, ‘0001’), (‘002’, ‘0001’), (‘005’, ‘0001’), (‘009’, ‘0002’), (‘010’, ‘0002’), (‘011’, ‘0001’), (‘014’, ‘0001’), (‘015’, ‘0001’), (‘016’, ‘0001’), (‘017’, ‘0001’), (‘018’, ‘0001’)  Total excluded combinations across all districts: 53  Data shape after exclusions: (890, 10)  Rows removed: 702 Why Exclusion was done? Here Column 1 represents the IV units and Column 2 represents the number of blocks in a IV unit. Although IV units are defined as holding 20 to 40 blocks, in many cases they contain far fewer blocks, which may result in an insufficient number of blocks for sampling. Will this exclusion process be avoided in some cases? Yes, in some cases the exclusion process completely eliminates all the IV units in a district, making it impossible to carry out sampling for that district under the general strategy. This occurs when all the IV units have fewer than 20 blocks, and the number of blocks is quite unpredictable—sometimes even as low as one block per IV unit. Therefore, to retain such districts, the exclusion process is avoided.” However, It is a very rare case. Cluster Calculation and Proportional Allocation This step implements the core statistical methodology for cluster sampling: Sampling Strategy: 1. IV unit Count: Counts unique IV Units per district 2. Proportional Allocation: Distributes target clusters based on district size with respect to the number of IV units Key Calculations: - District Proportion = IV Units in District / Total IV Units - Allocated Clusters = Target Clusters × District Proportion - Minimum Allocation: Each district gets at least 1 cluster (+1 adjustment) User Input: Total number of clusters to be selected for the survey Output: District-wise cluster allocation plan with verification totals. Code # ============================================================================= # STEP 4: CLUSTER CALCULATION AND ALLOCATION # ============================================================================= print(&quot;\\n&quot; + &quot;=&quot;*80) print(&quot;STEP 4: CLUSTER CALCULATION AND ALLOCATION&quot;) print(&quot;=&quot;*80) # Count unique IV units per district and town g = filtered_df1.iloc[:, :8].groupby(by=[&quot;D_Code&quot;, &quot;T_Code&quot;])[[&#39;IV_Unit_No&#39;]].nunique() print(&quot; IV Units per District-Town combination:&quot;) print(g.head(10)) # Sum up total clusters per district unique_iv_unit_counts = g.groupby(by=[&quot;D_Code&quot;]).sum() print(f&quot;\\n Total IV Units per district:&quot;) print(unique_iv_unit_counts) # Calculate proportions unique_iv_unit_counts_proportion = unique_iv_unit_counts / unique_iv_unit_counts.sum() unique_iv_unit_counts[&#39;Proportion&#39;] = unique_iv_unit_counts_proportion print(f&quot;\\n District proportions:&quot;) print(unique_iv_unit_counts[[&#39;IV_Unit_No&#39;, &#39;Proportion&#39;]]) # Get total number of clusters from user num_clusters = int(input(&quot;Enter the total number of clusters to select: &quot;)) print(f&quot; Target total clusters: {num_clusters}&quot;) # Allocate clusters proportionally to each district unique_iv_unit_counts[&#39;No_of_Cluster&#39;] = (unique_iv_unit_counts_proportion * num_clusters) unique_iv_unit_counts[&#39;No_of_Cluster&#39;] = unique_iv_unit_counts[&#39;No_of_Cluster&#39;].apply(int) + 1 print(f&quot;\\n Cluster allocation per district:&quot;) print(unique_iv_unit_counts[[&#39;IV_Unit_No&#39;, &#39;Proportion&#39;, &#39;No_of_Cluster&#39;]]) # Add district names to results district_names = df[[&#39;D_Code&#39;, &#39;District&#39;]].drop_duplicates() result = pd.merge(unique_iv_unit_counts, district_names, on=&#39;D_Code&#39;, how=&#39;left&#39;) result = result[[&#39;D_Code&#39;, &#39;District&#39;, &#39;IV_Unit_No&#39;, &#39;Proportion&#39;, &#39;No_of_Cluster&#39;]] print(f&quot;\\n Final cluster allocation:&quot;) print(result.to_string(index=False)) # Verify total allocated clusters total_allocated = result[&#39;No_of_Cluster&#39;].sum() print(f&quot;\\n✅ Total clusters allocated: {total_allocated}&quot;) print(f&quot; Target clusters: {num_clusters}&quot;) print(f&quot; Difference: {total_allocated - num_clusters}&quot;)  Total IV Units per district D_Code IV_Unit_No 01 14 02 18  District proportions D_Code IV_Unit_No Proportion 01 14 0.4375 02 18 0.5625  Target total clusters: 131  Final cluster allocation D_Code District IV_Unit_No Proportion No_of_Cluster 01 North Goa 14 0.4375 58 02 South Goa 18 0.5625 74 ✅ Total clusters allocated: 132  Target clusters: 131  Difference: 1 Utility Functions for Report Generation This section defines helper functions for creating professional output reports: Excel Generation Functions: - extract_clusters_to_excel(): Creates multi-sheet Excel workbooks with one sheet per district - Formats data with proper headers and structure PDF Generation Functions: - add_text_page(): Adds formatted text content to PDF documents - create_table_pdf(): Generates professional tables with styling - Handles page breaks and font formatting Data Formatting Functions: - format_excluded_combinations(): Creates readable summaries of excluded IV Units - Provides clear documentation of data quality decisions Purpose: These functions enable automated generation of professional reports for survey planning and documentation, ensuring consistent formatting and comprehensive coverage of sampling decisions. Code # ============================================================================= # UTILITY FUNCTIONS FOR EXCEL AND PDF GENERATION # ============================================================================= def extract_clusters_to_excel(selected_clusters, output_file): &quot;&quot;&quot;Create Excel file with separate sheets for each district&quot;&quot;&quot; workbook = Workbook() workbook.remove(workbook.active) # Remove default sheet for district_code, df in selected_clusters.items(): if not df.empty: sheet_name = f&quot;District_{district_code}&quot; worksheet = workbook.create_sheet(title=sheet_name) # Add headers worksheet.append(list(df.columns)) # Add data for row in df.values.tolist(): worksheet.append(row) workbook.save(output_file) print(f&quot;✅ Excel file created: {output_file}&quot;) def add_text_page(pdf_canvas, text): &quot;&quot;&quot;Add text content to PDF canvas&quot;&quot;&quot; pdf_canvas.setFont(&quot;CourierNew&quot;, 12) text_lines = text.split(&#39;\\n&#39;) y_position = 800 for line in text_lines: if y_position &lt; 50: pdf_canvas.showPage() pdf_canvas.setFont(&quot;CourierNew&quot;, 12) y_position = 800 pdf_canvas.drawString(72, y_position, line) y_position -= 14 pdf_canvas.showPage() def create_table_pdf(df, output_path): &quot;&quot;&quot;Create PDF with table from DataFrame&quot;&quot;&quot; doc = SimpleDocTemplate(output_path, pagesize=A4) table_data = [df.columns.tolist()] + df.values.tolist() table = Table(table_data) style = TableStyle([ (&#39;BACKGROUND&#39;, (0, 0), (-1, 0), colors.grey), (&#39;TEXTCOLOR&#39;, (0, 0), (-1, 0), colors.whitesmoke), (&#39;ALIGN&#39;, (0, 0), (-1, -1), &#39;CENTER&#39;), (&#39;FONTNAME&#39;, (0, 0), (-1, 0), &#39;CourierNew&#39;), (&#39;FONTNAME&#39;, (0, 1), (-1, -1), &#39;CourierNew&#39;), (&#39;BOTTOMPADDING&#39;, (0, 0), (-1, 0), 12), (&#39;BACKGROUND&#39;, (0, 1), (-1, -1), colors.white), (&#39;GRID&#39;, (0, 0), (-1, -1), 1, colors.black), ]) table.setStyle(style) doc.build([table]) def format_excluded_combinations(excluded_dict): &quot;&quot;&quot;Format excluded combinations for display&quot;&quot;&quot; if not excluded_dict: return &quot;No IV Units were excluded based on the frequency criteria.\\n&quot; formatted_text = &quot;District wise excluded IV Units:\\n\\n&quot; for district, exclusions in excluded_dict.items(): formatted_text += f&quot;District Code: {district}\\n&quot; formatted_text += &quot;Town_Code || IV_Unit_No\\n&quot; formatted_text += &quot;-&quot; * 25 + &quot;\\n&quot; for town_code, iv_unit_no in exclusions: formatted_text += f&quot;{town_code:&lt;10} || {iv_unit_no}\\n&quot; formatted_text += &quot;\\n&quot; return formatted_text  RESULT SUMMARY State Name: Goa State Code: 30 District Codes: 01, 02 Total Clusters Requested: 131 Total Clusters Allocated: 132 Exclusion Applied: Yes  Cluster Allocation by District D_Code District IV_Unit_No Proportion No_of_Cluster 01 North Goa 14 0.4375 58 02 South Goa 18 0.5625 74 Result Summary and Sampling Preparation This step creates a comprehensive summary of the sampling plan and prepares for execution: Summary Components: 1. Metadata: State name, state code, selected districts 2. Allocation Summary: Target vs. allocated clusters 3. Quality Control: Documentation of exclusions applied 4. District Breakdown: Detailed allocation table Iteration Setup: - Multiple Samples: Allows generation of multiple independent samples - Reproducibility: Each iteration creates a different random sample Code # ============================================================================= # STEP 5: PREPARE RESULT SUMMARY # ============================================================================= print(&quot;\\n&quot; + &quot;=&quot;*80) print(&quot;STEP 5: PREPARING RESULT SUMMARY&quot;) print(&quot;=&quot;*80) result_string = [] result_string.append(&#39;\\n\\nRESULT SUMMARY&#39;) result_string.append(f&#39;State Name: {df.iloc[0, 1]}&#39;) result_string.append(f&#39;State Code: {df.iloc[0, 0]}&#39;) result_string.append(f&#39;District Codes: {&quot; &quot;.join(D_Code_list)}&#39;) result_string.append(f&#39;Total Clusters Requested: {num_clusters}&#39;) result_string.append(f&#39;Total Clusters Allocated: {total_allocated}&#39;) result_string.append(f&#39;Exclusion Applied: {&quot;Yes&quot; if Excluder else &quot;No&quot;}&#39;) result_string.append(&#39;\\n&#39; + &#39;-&#39;*55) result_string.append(result.to_string(index=False)) final_result = &#39;\\n&#39;.join(result_string) print(final_result) # Get number of sample iterations from user multiplier = int(input(&quot;Enter number of sample iterations to generate (usually 1): &quot;) or &quot;1&quot;) print(f&quot; Will generate {multiplier} independent sample(s)&quot;) Random Cluster Sampling Implementation Two-Stage Sampling Process Stage 1: IV Unit Selection - Random selection of IV Units from each district - Uses allocated cluster counts from Step 4 - Implements replacement logic when needed Stage 2: Block Selection - Within selected IV Units, randomly samples UFS blocks - Ensures actual sample size matches allocation Procedure for Sampling IV Units When sufficient IV units are available If the number of IV units (num_iv_units) is greater than or equal to the required number of clusters (num_clusters_for_district), A random sample of the required size is drawn without replacement, ensuring no IV unit is selected more than once. When insufficient IV units are available If the number of available IV units is less than the required number of clusters, First, all available IV units are selected without replacement. Then, the remaining IV units needed to reach the required number of clusters are drawn with replacement, allowing some IV units to be selected more than once. Frequency of IV Unit Selection and Block Sampling The frequency of IV unit selection determines how many blocks must be sampled from that IV unit. Without replacement case: When there are enough IV units, only one block is sampled per IV unit. With replacement case: Since some IV units are selected more than once, multiple blocks must be sampled from those IV units. For each IV unit selected: - The total number of blocks available is checked. - If the number of available blocks is greater than or equal to the required frequency, exactly that many blocks are sampled without replacement. - If the number of available blocks is less than the required frequency, all available blocks are taken. However, this did not occur in any case, as having a minimum of 20 blocks per IV unit was sufficient in all situations. Importance of Exclusion and Combined Sampling Strategy The exclusion condition defined earlier is essential, because if an IV unit does not have enough blocks, proper sampling cannot be carried out. The combination of with- and without-replacement sampling ensures maximum representativeness of IV units. In some cases, this approach includes all IV units in the sampling process, improving district coverage. Output: Dictionary of selected clusters organized by district, ready for geocoding and reporting. Code # ============================================================================= # STEP 6: CLUSTER SAMPLING AND REPORT GENERATION # ============================================================================= print(&quot;\\n&quot; + &quot;=&quot;*80) print(&quot;STEP 6: CLUSTER SAMPLING AND REPORT GENERATION&quot;) print(&quot;=&quot;*80) for z in range(multiplier): print(f&quot;\\n Processing iteration {z+1}/{multiplier}&quot;) selected_clusters = {} # Sample clusters for each district for district_code, row in unique_iv_unit_counts.iterrows(): print(f&quot;\\n Sampling for District: {district_code}&quot;) num_clusters_for_district = int(row[&#39;No_of_Cluster&#39;]) num_iv_units = int(row[&#39;IV_Unit_No&#39;]) print(f&quot;  Target clusters: {num_clusters_for_district}&quot;) print(f&quot;  Available IV units: {num_iv_units}&quot;) # Get data for this district district_df = filtered_df1[filtered_df1[&#39;D_Code&#39;] == district_code] print(f&quot;  District data rows: {len(district_df)}&quot;) # Get unique IV units in this district unique_df = district_df.drop_duplicates(subset=[&#39;T_Code&#39;, &#39;IV_Unit_No&#39;])[[&#39;T_Code&#39;, &#39;IV_Unit_No&#39;]] print(f&quot;  Unique IV units available: {len(unique_df)}&quot;) # Sample IV units (with or without replacement) if num_iv_units &gt;= num_clusters_for_district: sampled_df = unique_df.sample(n=num_clusters_for_district, replace=False) print(f&quot; ✅ Sampled {num_clusters_for_district} IV units without replacement&quot;) else: sampled_df = pd.concat([ unique_df.sample(n=unique_df.shape[0], replace=False), unique_df.sample(n=num_clusters_for_district - unique_df.shape[0], replace=True) ]) print(f&quot; ⚠️ Sampled with replacement (needed {num_clusters_for_district}, had {num_iv_units})&quot;) # Count frequency of selected IV units frequency_df = sampled_df.groupby([&#39;T_Code&#39;, &#39;IV_Unit_No&#39;]).size().reset_index(name=&#39;Frequency&#39;) print(f&quot;  IV unit frequency distribution:&quot;) print(f&quot; {frequency_df.to_string(index=False)}&quot;) # Sample UFS blocks from selected IV units UFS_samples = [] for _, row2 in frequency_df.iterrows(): t_code = row2[&#39;T_Code&#39;] iv_unit_no = row2[&#39;IV_Unit_No&#39;] freq = row2[&#39;Frequency&#39;] # Get all blocks for this IV unit available_blocks = district_df[(district_df[&#39;T_Code&#39;] == t_code) &amp; (district_df[&#39;IV_Unit_No&#39;] == iv_unit_no)] N = available_blocks.shape[0] # Sample blocks (cannot sample more than available) if N &lt; freq: UFS_sample = available_blocks.sample(n=N, replace=False) print(f&quot; ⚠️ Town {t_code}, IV {iv_unit_no}: sampled {N} blocks (needed {freq})&quot;) else: UFS_sample = available_blocks.sample(n=freq, replace=False) print(f&quot; ✅ Town {t_code}, IV {iv_unit_no}: sampled {freq} blocks from {N} available&quot;) UFS_samples.append(UFS_sample) # Combine all samples for this district selected_clusters[district_code] = pd.concat(UFS_samples, ignore_index=True) print(f&quot;  Total selected blocks for district: {len(selected_clusters[district_code])}&quot;) # Show summary of this iteration print(f&quot;\\n✅ ITERATION {z+1} SAMPLING COMPLETE&quot;) print(f&quot; Summary of selected clusters:&quot;) for district_code, df_dist in selected_clusters.items(): print(f&quot; District {district_code}: {len(df_dist)} clusters selected&quot;)  Sampling Iteration Results Number of iterations: 1  District 01 — North Goa  Target clusters: 58  Available IV units: 14  District data rows: 370  Unique IV units available: 14 ⚠️ Sampled with replacement (needed 58, had 14)  IV Unit Frequency Distribution (Result of SRS) T_Code IV_Unit_No Frequency 003 0001 1 004 0001 3 005 0001 2 006 0001 7 009 0001 5 014 0001 4 016 0004 5 018 0001 7 020 0001 5 036 0001 2 037 0001 3 041 0001 8 043 0001 4 047 0001 2 ✅ Block Sampling Summary - Town 003, IV 0001 → 1 / 20 blocks - Town 004, IV 0001 → 3 / 23 blocks - Town 005, IV 0001 → 2 / 28 blocks - Town 006, IV 0001 → 7 / 20 blocks - Town 009, IV 0001 → 5 / 23 blocks - Town 014, IV 0001 → 4 / 31 blocks - Town 016, IV 0004 → 5 / 32 blocks - Town 018, IV 0001 → 7 / 39 blocks - Town 020, IV 0001 → 5 / 29 blocks - Town 036, IV 0001 → 2 / 30 blocks - Town 037, IV 0001 → 3 / 21 blocks - Town 041, IV 0001 → 8 / 29 blocks - Town 043, IV 0001 → 4 / 25 blocks - Town 047, IV 0001 → 2 / 20 blocks  Total selected blocks: 58  District 02 — South Goa  Target clusters: 74  Available IV units: 18  District data rows: 520  Unique IV units available: 18 ⚠️ Sampled with replacement (needed 74, had 18)  IV Unit Frequency Distribution (Result of SRS) T_Code IV_Unit_No Frequency 003 0001 3 004 0001 4 006 0001 7 007 0001 3 008 0001 4 009 0001 3 009 0003 6 009 0004 4 009 0005 2 009 0006 4 010 0001 5 010 0003 5 010 0004 7 010 0005 1 012 0001 5 013 0001 3 019 0001 5 021 0001 3 ✅ Block Sampling Summary - Town 003, IV 0001 → 3 / 23 blocks - Town 004, IV 0001 → 4 / 21 blocks - Town 006, IV 0001 → 7 / 25 blocks - Town 007, IV 0001 → 3 / 31 blocks - Town 008, IV 0001 → 4 / 24 blocks - Town 009, IV 0001 → 3 / 32 blocks - Town 009, IV 0003 → 6 / 25 blocks - Town 009, IV 0004 → 4 / 46 blocks - Town 009, IV 0005 → 2 / 29 blocks - Town 009, IV 0006 → 4 / 33 blocks - Town 010, IV 0001 → 5 / 32 blocks - Town 010, IV 0003 → 5 / 24 blocks - Town 010, IV 0004 → 7 / 38 blocks - Town 010, IV 0005 → 1 / 32 blocks - Town 012, IV 0001 → 5 / 22 blocks - Town 013, IV 0001 → 3 / 30 blocks - Town 019, IV 0001 → 5 / 29 blocks - Town 021, IV 0001 → 3 / 24 blocks  Total selected blocks: 74 Geographic Coordinate Assignment (Geocoding) This step adds spatial coordinates to enable mapping and geographic analysis: Geocoding Process: 1. Location Query: Constructs queries using “Town, District, State” format 2. Service Provider: Uses ArcGIS geocoding service via geopy library 3. Coordinate Extraction: Retrieves latitude and longitude for each location 4. Error Handling: Manages failed geocoding attempts gracefully Data Enhancement: - Spatial Coordinates: Adds Latitude and Longitude columns - Quality Reporting: Tracks successful vs. failed geocoding attempts - Coverage Analysis: Reports geocoding success rates by district Code # ============================================================================= # STEP 7: GEOCODING # ============================================================================= print(f&quot;\\n STEP 7: GEOCODING SELECTED LOCATIONS&quot;) print(&quot;-&quot; * 50) locator = geopy.geocoders.ArcGIS(user_agent=&quot;mygeocoder&quot;) for district_code, df_dist in selected_clusters.items(): if not df_dist.empty: print(f&quot;\\n Geocoding for District {district_code}...&quot;) for index, row in df_dist.iterrows(): try: # Create location query using town, district, and state location_query = f&quot;{row[&#39;Town&#39;]}, {row[&#39;District&#39;]}, {state_name}&quot; location = locator.geocode(location_query) if location: df_dist.loc[index, &#39;Latitude&#39;] = location.latitude df_dist.loc[index, &#39;Longitude&#39;] = location.longitude print(f&quot; ✅ {row[&#39;Town&#39;]}: ({location.latitude:.4f}, {location.longitude:.4f})&quot;) else: df_dist.loc[index, &#39;Latitude&#39;] = None df_dist.loc[index, &#39;Longitude&#39;] = None print(f&quot; ❌ {row[&#39;Town&#39;]}: Location not found&quot;) except Exception as e: print(f&quot; ❌ Error geocoding {row[&#39;Town&#39;]}: {e}&quot;) df_dist.loc[index, &#39;Latitude&#39;] = None df_dist.loc[index, &#39;Longitude&#39;] = None # Show geocoding summary for this district geocoded_count = df_dist[&#39;Latitude&#39;].notna().sum() total_count = len(df_dist) print(f&quot;  Geocoded {geocoded_count}/{total_count} locations ({geocoded_count/total_count*100:.1f}%)&quot;) Output Generation and Final Documentation This final step generates comprehensive outputs and provides project completion summary: Output Files Generated: 1. Excel Reports: Multi-sheet workbooks with one sheet per district - Contains all selected cluster details - Includes geographic coordinates - Formatted for field use Directory Structure: Creates organized folder system map/: Reserved for mapping outputs temp/: Temporary processing files GIS/: Geospatial data files Quality Assurance: - Sample Verification: Displays sample of selected clusters - Count Validation: Verifies cluster counts match allocation - Coordinate Check: Shows geocoding success rates Final Summary: - Iteration Tracking: Documents number of independent samples generated - File Naming: Uses standardized naming convention with state identifiers - Performance Metrics: Reports total clusters and processing statistics Deliverables: Ready-to-use cluster sampling results for urban survey implementation, complete with coordinates and detailed documentation for field teams. Code # ============================================================================= # STEP 8: GENERATE OUTPUT FILES # ============================================================================= print(f&quot;\\n STEP 8: GENERATING OUTPUT FILES&quot;) print(&quot;-&quot; * 50) # Generate Excel output excel_filename = f&quot;Urban Report[EXCEL-{z+1}]-{state_name}_{state_code}.xlsx&quot; extract_clusters_to_excel(selected_clusters, output_file=excel_filename) # Create directories if they don&#39;t exist os.makedirs(&quot;map&quot;, exist_ok=True) os.makedirs(&quot;temp&quot;, exist_ok=True) os.makedirs(&quot;GIS&quot;, exist_ok=True) print(f&quot;\\n✅ PROCESSING COMPLETE FOR ITERATION {z+1}&quot;) print(f&quot; Summary of selected clusters:&quot;) for district_code, df_dist in selected_clusters.items(): print(f&quot; District {district_code}: {len(df_dist)} clusters selected&quot;) # Display first few selected clusters for verification print(f&quot;\\n Sample of selected clusters:&quot;) sample_df = pd.concat(selected_clusters.values()).head(10) print(sample_df[[&#39;District&#39;, &#39;Town&#39;, &#39;IV_Unit_No&#39;, &#39;Block_No&#39;, &#39;Latitude&#39;, &#39;Longitude&#39;]].to_string(index=False)) print(f&quot;\\n ALL ITERATIONS COMPLETED!&quot;) print(f&quot; Output files generated with prefix: Urban Report[EXCEL]-{state_name}_{state_code}&quot;) print(f&quot; Total sample iterations: {multiplier}&quot;) # Final summary total_clusters_generated = sum(len(df_dist) for df_dist in selected_clusters.values()) print(f&quot; Clusters per iteration: ~{total_clusters_generated}&quot;) print(f&quot; Total clusters across all iterations: ~{total_clusters_generated * multiplier}&quot;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
